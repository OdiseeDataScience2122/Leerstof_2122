{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "201dc5f5",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbours\n",
    "\n",
    "De Naive Bayes techniek is een **supervised** machine learning techniek voor **classificatie** problemen op te lossen.\n",
    "Deze techniek bestaat reeds sinds de jaren 50.\n",
    "Het unieke aan deze techniek is dat er geen parameters getrained moeten worden maar dat de k dichtste buren van de input gebruikt worden om de output te bepalen.\n",
    "De k-waarde hierbij is een hyperparameter.\n",
    "Het algoritme kan gebruikt worden voor zowel classificatie als regressie:\n",
    "* In het geval van classificatie is de resulterende klasse de meest voorkomende klasse van de k-dichtste buren.\n",
    "* In het geval van regressie is de voorspelling het gemiddelde van de target van de k-dichtste buren.\n",
    "\n",
    "De afstand tussen verschillende inputs heeft duidelijk een grote invloed op welke buren geselecteerd worden voor het uitvoeren techniek.\n",
    "Hierdoor is het duidelijk dat het de schaal van de verschillende inputs een grote impact kan hebben en dat **normalisatie** van de verschillende inputs belangrijk is. \n",
    "\n",
    "Deze techniek gaat het best werken indien zowel het aantal features als het aantal observaties niet te groot is.\n",
    "Indien het aantal features groot is gaat het moeilijk zijn om een correcte afstand tussen verschillende observaties te bepalen.\n",
    "Het probleem met een groot aantal observaties is dat om een classificatie te doen, de afstand tot elk punt in de dataset moet berekend worden.\n",
    "De benodigde tijd voor het uitvoeren van een classificatie kan dus zeer snel toenemen bij grote datasets.\n",
    "\n",
    "Een uitbreiding op het standaard algoritme hierboven beschreven is om een bepaald gewicht toe te kennen aan elke buur afhankelijk van de afstand tot die buur.\n",
    "Een vaak gebruikt gewicht is het inverse van de afstand.\n",
    "Hierdoor wordt er een groter gewicht gegeven aan dichte buren en verminderd de kans op ex aequo tussen de verschillende buren.\n",
    "\n",
    "Hieronder bekijken we een voorbeeld van hoe dit type classifier te implementeren door middel van de [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) van sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40150027",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9711d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.9333333333333333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1, weights=\"uniform\")\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(knn.score(X_train, y_train))\n",
    "print(knn.score(X_test, y_test))\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d21a872",
   "metadata": {},
   "source": [
    "Er kan nu hyperparameter tuning toegepast worden op de k-waarde om het beste model te zoeken.\n",
    "Algemeen gezien gelden de volgende regels:\n",
    "* Een grote K waarde gebruikt meer buren en gaat dus een smoothere scheidingslijn geven. (Minder complex model dat kan leiden tot underfitting)\n",
    "* Een kleinere K waarde zorgt voor snellere wisseling van dominante klasse en dus tot een complexer model dat kan leiden tot overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f0486d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a8f3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
